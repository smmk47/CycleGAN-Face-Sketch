{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3724153,"sourceType":"datasetVersion","datasetId":2151228},{"sourceId":201938879,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport itertools\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\n# Define device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Custom Dataset\nclass FaceSketchDataset(Dataset):\n    def __init__(self, root_dir, transforms_=None, mode='train'):\n        self.transform = transforms_\n        self.mode = mode\n        photos_dir = os.path.join(root_dir, mode, 'photos')\n        sketches_dir = os.path.join(root_dir, mode, 'sketches')\n        \n        # Ensure directories exist\n        if not os.path.isdir(photos_dir):\n            raise FileNotFoundError(f\"Directory not found: {photos_dir}\")\n        if not os.path.isdir(sketches_dir):\n            raise FileNotFoundError(f\"Directory not found: {sketches_dir}\")\n        \n        self.img_A_paths = sorted(os.listdir(photos_dir))\n        self.img_B_paths = sorted(os.listdir(sketches_dir))\n        self.root_dir = root_dir\n\n    def __len__(self):\n        return max(len(self.img_A_paths), len(self.img_B_paths))\n\n    def __getitem__(self, idx):\n        A_path = os.path.join(self.root_dir, self.mode, 'photos', self.img_A_paths[idx % len(self.img_A_paths)])\n        B_path = os.path.join(self.root_dir, self.mode, 'sketches', self.img_B_paths[idx % len(self.img_B_paths)])\n        A = Image.open(A_path).convert('RGB')\n        B = Image.open(B_path).convert('RGB')\n        if self.transform:\n            A = self.transform(A)\n            B = self.transform(B)\n        return {'A': A, 'B': B}\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize(int(256 * 1.12), Image.BICUBIC),\n    transforms.RandomCrop(256),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Create DataLoaders\ndef get_dataloaders(root_dir, batch_size=4):\n    train_dataset = FaceSketchDataset(root_dir, transforms_=transform, mode='train')\n    val_dataset = FaceSketchDataset(root_dir, transforms_=transform, mode='val')\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n    return train_loader, val_loader\n\n# Example usage:\nroot_dir = '/kaggle/input/person-face-sketches'\ntrain_loader, val_loader = get_dataloaders(root_dir, batch_size=4)  # Set batch_size to 4\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Residual Block\nclass ResidualBlock(nn.Module):\n    def __init__(self, features):\n        super(ResidualBlock, self).__init__()\n        self.block = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(features, features, kernel_size=3, stride=1, padding=0),\n            nn.InstanceNorm2d(features),\n            nn.ReLU(inplace=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(features, features, kernel_size=3, stride=1, padding=0),\n            nn.InstanceNorm2d(features)\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\n# Generator\nclass Generator(nn.Module):\n    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n        super(Generator, self).__init__()\n\n        # Initial convolution block\n        model = [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(input_nc, 64, kernel_size=7, padding=0),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True)\n        ]\n\n        # Downsampling\n        in_features = 64\n        out_features = in_features * 2\n        for _ in range(2):\n            model += [\n                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n            in_features = out_features\n            out_features = in_features * 2\n\n        # Residual blocks\n        for _ in range(n_residual_blocks):\n            model += [ResidualBlock(in_features)]\n\n        # Upsampling\n        out_features = in_features // 2\n        for _ in range(2):\n            model += [\n                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2,\n                                   padding=1, output_padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n            in_features = out_features\n            out_features = in_features // 2\n\n        # Output layer\n        model += [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(in_features, output_nc, kernel_size=7),\n            nn.Tanh()\n        ]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)\n\n\n# Discriminator\nclass Discriminator(nn.Module):\n    def __init__(self, input_nc):\n        super(Discriminator, self).__init__()\n\n        # A series of convolutional layers\n        model = [\n            nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True)\n        ]\n\n        model += [\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True)\n        ]\n\n        model += [\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.InstanceNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True)\n        ]\n\n        model += [\n            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1),\n            nn.InstanceNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True)\n        ]\n\n        # Output layer\n        model += [nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)\n\n\n# Initialize generators and discriminators\nG_A2B = Generator(input_nc=3, output_nc=3).to(device)\nG_B2A = Generator(input_nc=3, output_nc=3).to(device)\nD_A = Discriminator(input_nc=3).to(device)\nD_B = Discriminator(input_nc=3).to(device)\n\n# Initialize weights\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    if hasattr(m, 'weight') and m.weight is not None:\n        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n            nn.init.normal_(m.weight, 0.0, 0.02)\n        elif isinstance(m, (nn.BatchNorm2d, nn.InstanceNorm2d)):\n            nn.init.normal_(m.weight, 1.0, 0.02)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0.0)\n\nG_A2B.apply(weights_init_normal)\nG_B2A.apply(weights_init_normal)\nD_A.apply(weights_init_normal)\nD_B.apply(weights_init_normal)\n\nimport torch.optim as optim\n\n# Loss functions\ncriterion_GAN = nn.MSELoss().to(device)\ncriterion_cycle = nn.L1Loss().to(device)\ncriterion_identity = nn.L1Loss().to(device)\n\n# Optimizers\nlr = 0.0002\nbeta1 = 0.5\nbeta2 = 0.999\n\noptimizer_G = optim.Adam(itertools.chain(G_A2B.parameters(), G_B2A.parameters()), lr=lr, betas=(beta1, beta2))\noptimizer_D_A = optim.Adam(D_A.parameters(), lr=lr, betas=(beta1, beta2))\noptimizer_D_B = optim.Adam(D_B.parameters(), lr=lr, betas=(beta1, beta2))\n\n# Learning rate schedulers\nfrom torch.optim import lr_scheduler\n\nlr_lambda = lambda epoch: 1.0 - max(0, epoch - 100) / float(100)\nscheduler_G = lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lr_lambda)\nscheduler_D_A = lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lr_lambda)\nscheduler_D_B = lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lr_lambda)\n\n# Buffers to store previously generated samples\nclass ReplayBuffer:\n    def __init__(self, max_size=50):\n        assert max_size > 0, 'Empty buffer or trying to create a buffer with negative size.'\n        self.max_size = max_size\n        self.data = []\n\n    def push_and_pop(self, data):\n        to_return = []\n        for element in data.data:\n            element = torch.unsqueeze(element, 0)\n            if len(self.data) < self.max_size:\n                self.data.append(element)\n                to_return.append(element)\n            else:\n                if torch.rand(1).item() > 0.5:\n                    idx = torch.randint(0, self.max_size, (1,)).item()\n                    to_return.append(self.data[idx].clone())\n                    self.data[idx] = element\n                else:\n                    to_return.append(element)\n        return torch.cat(to_return)\n\nfake_A_buffer = ReplayBuffer()\nfake_B_buffer = ReplayBuffer()\n\n# Function to load checkpoints\ndef load_checkpoint(epoch, checkpoint_dir):\n    G_A2B.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'G_A2B_epoch_{epoch}.pth')))\n    G_B2A.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'G_B2A_epoch_{epoch}.pth')))\n    D_A.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'D_A_epoch_{epoch}.pth')))\n    D_B.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'D_B_epoch_{epoch}.pth')))\n    print(f\"Loaded models for epoch {epoch}\")\n\n# Define checkpoint directory\ncheckpoint_dir = '/kaggle/input/question-4/checkpoints'  # Update this path if different\n\n# Example: Load models from epoch 1 and start training from epoch 2\nstarting_epoch = 1\ntry:\n    load_checkpoint(starting_epoch, checkpoint_dir)\n    starting_epoch += 1  # Start from the next epoch\nexcept FileNotFoundError:\n    print(f\"No checkpoint found at epoch {starting_epoch}. Starting from scratch.\")\n\n# Training Loop\nnum_epochs = 50\ntrain_loader, val_loader = get_dataloaders(root_dir, batch_size=4)  # Ensure batch_size is set to 4\n\nfor epoch in range(starting_epoch, num_epochs + 1):\n    G_A2B.train()\n    G_B2A.train()\n    D_A.train()\n    D_B.train()\n    \n    for i, batch in enumerate(train_loader):\n        real_A = batch['A'].to(device)\n        real_B = batch['B'].to(device)\n\n        # Adversarial ground truths\n        valid = torch.ones((real_A.size(0), 1, 30, 30), requires_grad=False).to(device)\n        fake = torch.zeros((real_A.size(0), 1, 30, 30), requires_grad=False).to(device)\n\n        ###### Generators A2B and B2A ######\n        optimizer_G.zero_grad()\n\n        # Identity loss\n        same_B = G_A2B(real_B)\n        loss_identity_B = criterion_identity(same_B, real_B) * 5.0\n        same_A = G_B2A(real_A)\n        loss_identity_A = criterion_identity(same_A, real_A) * 5.0\n\n        # GAN loss\n        fake_B = G_A2B(real_A)\n        pred_fake = D_B(fake_B)\n        loss_GAN_A2B = criterion_GAN(pred_fake, valid)\n\n        fake_A = G_B2A(real_B)\n        pred_fake = D_A(fake_A)\n        loss_GAN_B2A = criterion_GAN(pred_fake, valid)\n\n        # Cycle loss\n        recovered_A = G_B2A(fake_B)\n        loss_cycle_ABA = criterion_cycle(recovered_A, real_A) * 10.0\n\n        recovered_B = G_A2B(fake_A)\n        loss_cycle_BAB = criterion_cycle(recovered_B, real_B) * 10.0\n\n        # Total loss\n        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n        loss_G.backward()\n        optimizer_G.step()\n\n        ###### Discriminator A ######\n        optimizer_D_A.zero_grad()\n\n        # Real loss\n        pred_real = D_A(real_A)\n        loss_D_real = criterion_GAN(pred_real, valid)\n\n        # Fake loss\n        fake_A_buffered = fake_A_buffer.push_and_pop(fake_A)\n        pred_fake = D_A(fake_A_buffered.detach())\n        loss_D_fake = criterion_GAN(pred_fake, fake)\n\n        # Total loss\n        loss_D_A_total = (loss_D_real + loss_D_fake) * 0.5\n        loss_D_A_total.backward()\n        optimizer_D_A.step()\n\n        ###### Discriminator B ######\n        optimizer_D_B.zero_grad()\n\n        # Real loss\n        pred_real = D_B(real_B)\n        loss_D_real = criterion_GAN(pred_real, valid)\n\n        # Fake loss\n        fake_B_buffered = fake_B_buffer.push_and_pop(fake_B)\n        pred_fake = D_B(fake_B_buffered.detach())\n        loss_D_fake = criterion_GAN(pred_fake, fake)\n\n        # Total loss\n        loss_D_B_total = (loss_D_real + loss_D_fake) * 0.5\n        loss_D_B_total.backward()\n        optimizer_D_B.step()\n\n        if i % 500 == 0:\n            print(f\"Epoch [{epoch}/{num_epochs}] Batch [{i}/{len(train_loader)}] \"\n                  f\"Loss_G: {loss_G.item():.4f} Loss_D_A: {loss_D_A_total.item():.4f} \"\n                  f\"Loss_D_B: {loss_D_B_total.item():.4f}\")\n\n    # Update learning rates\n    scheduler_G.step()\n    scheduler_D_A.step()\n    scheduler_D_B.step()\n\n    # Save model checkpoints\n    save_checkpoint_dir = '/kaggle/working/checkpoints'  # Update this path as needed\n    os.makedirs(save_checkpoint_dir, exist_ok=True)\n    torch.save(G_A2B.state_dict(), os.path.join(save_checkpoint_dir, f'G_A2B_epoch_{epoch}.pth'))\n    torch.save(G_B2A.state_dict(), os.path.join(save_checkpoint_dir, f'G_B2A_epoch_{epoch}.pth'))\n    torch.save(D_A.state_dict(), os.path.join(save_checkpoint_dir, f'D_A_epoch_{epoch}.pth'))\n    torch.save(D_B.state_dict(), os.path.join(save_checkpoint_dir, f'D_B_epoch_{epoch}.pth'))\n    print(f\"Saved models for epoch {epoch}\")\n\n    print(f\"Completed epoch {epoch}/{num_epochs}\")\n\n# Optional: Function to load checkpoints (Already defined above)\ndef load_checkpoint(epoch, checkpoint_dir, G_A2B, G_B2A, D_A, D_B):\n    G_A2B.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'G_A2B_epoch_{epoch}.pth')))\n    G_B2A.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'G_B2A_epoch_{epoch}.pth')))\n    D_A.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'D_A_epoch_{epoch}.pth')))\n    D_B.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'D_B_epoch_{epoch}.pth')))\n    print(f\"Loaded models for epoch {epoch}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-10-19T06:17:43.606804Z","iopub.execute_input":"2024-10-19T06:17:43.607156Z","iopub.status.idle":"2024-10-19T17:54:35.720286Z","shell.execute_reply.started":"2024-10-19T06:17:43.607122Z","shell.execute_reply":"2024-10-19T17:54:35.718637Z"}},"outputs":[{"name":"stdout","text":"Loaded models for epoch 1\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/3180168554.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  G_A2B.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'G_A2B_epoch_{epoch}.pth')))\n/tmp/ipykernel_30/3180168554.py:250: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  G_B2A.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'G_B2A_epoch_{epoch}.pth')))\n/tmp/ipykernel_30/3180168554.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  D_A.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'D_A_epoch_{epoch}.pth')))\n/tmp/ipykernel_30/3180168554.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  D_B.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'D_B_epoch_{epoch}.pth')))\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/50] Batch [0/5164] Loss_G: 3.3103 Loss_D_A: 0.0284 Loss_D_B: 0.0721\nEpoch [2/50] Batch [500/5164] Loss_G: 3.1871 Loss_D_A: 0.0634 Loss_D_B: 0.1808\nEpoch [2/50] Batch [1000/5164] Loss_G: 2.6192 Loss_D_A: 0.1825 Loss_D_B: 0.0882\nEpoch [2/50] Batch [1500/5164] Loss_G: 3.2295 Loss_D_A: 0.0714 Loss_D_B: 0.0020\nEpoch [2/50] Batch [2000/5164] Loss_G: 2.3332 Loss_D_A: 0.2099 Loss_D_B: 0.4262\nEpoch [2/50] Batch [2500/5164] Loss_G: 4.0434 Loss_D_A: 0.2244 Loss_D_B: 0.0061\nEpoch [2/50] Batch [3000/5164] Loss_G: 3.7528 Loss_D_A: 0.2686 Loss_D_B: 0.0031\nEpoch [2/50] Batch [3500/5164] Loss_G: 2.7278 Loss_D_A: 0.2856 Loss_D_B: 0.0201\nEpoch [2/50] Batch [4000/5164] Loss_G: 3.3284 Loss_D_A: 0.2205 Loss_D_B: 0.0098\nEpoch [2/50] Batch [4500/5164] Loss_G: 3.4815 Loss_D_A: 0.1992 Loss_D_B: 0.0028\nEpoch [2/50] Batch [5000/5164] Loss_G: 4.3149 Loss_D_A: 0.1719 Loss_D_B: 0.0034\nSaved models for epoch 2\nCompleted epoch 2/50\nEpoch [3/50] Batch [0/5164] Loss_G: 3.8351 Loss_D_A: 0.2576 Loss_D_B: 0.0028\nEpoch [3/50] Batch [500/5164] Loss_G: 3.2421 Loss_D_A: 0.1634 Loss_D_B: 0.0079\nEpoch [3/50] Batch [1000/5164] Loss_G: 3.5480 Loss_D_A: 0.1517 Loss_D_B: 0.0014\nEpoch [3/50] Batch [1500/5164] Loss_G: 4.7136 Loss_D_A: 0.0526 Loss_D_B: 0.1544\nEpoch [3/50] Batch [2000/5164] Loss_G: 3.2899 Loss_D_A: 0.1186 Loss_D_B: 0.0034\nEpoch [3/50] Batch [2500/5164] Loss_G: 2.6640 Loss_D_A: 0.1648 Loss_D_B: 0.2035\nEpoch [3/50] Batch [3000/5164] Loss_G: 2.8688 Loss_D_A: 0.0959 Loss_D_B: 0.0810\nEpoch [3/50] Batch [3500/5164] Loss_G: 3.3437 Loss_D_A: 0.0417 Loss_D_B: 0.0056\nEpoch [3/50] Batch [4000/5164] Loss_G: 3.0296 Loss_D_A: 0.1469 Loss_D_B: 0.0039\nEpoch [3/50] Batch [4500/5164] Loss_G: 3.6532 Loss_D_A: 0.0898 Loss_D_B: 0.0625\nEpoch [3/50] Batch [5000/5164] Loss_G: 3.3495 Loss_D_A: 0.1515 Loss_D_B: 0.0613\nSaved models for epoch 3\nCompleted epoch 3/50\nEpoch [4/50] Batch [0/5164] Loss_G: 2.6446 Loss_D_A: 0.2887 Loss_D_B: 0.0144\nEpoch [4/50] Batch [500/5164] Loss_G: 2.4508 Loss_D_A: 0.2723 Loss_D_B: 0.0807\nEpoch [4/50] Batch [1000/5164] Loss_G: 2.0495 Loss_D_A: 0.2599 Loss_D_B: 0.2322\nEpoch [4/50] Batch [1500/5164] Loss_G: 2.7743 Loss_D_A: 0.2019 Loss_D_B: 0.0030\nEpoch [4/50] Batch [2000/5164] Loss_G: 2.4718 Loss_D_A: 0.1807 Loss_D_B: 0.0041\nEpoch [4/50] Batch [2500/5164] Loss_G: 2.8307 Loss_D_A: 0.2418 Loss_D_B: 0.0017\nEpoch [4/50] Batch [3000/5164] Loss_G: 2.7480 Loss_D_A: 0.2249 Loss_D_B: 0.0026\nEpoch [4/50] Batch [3500/5164] Loss_G: 2.7215 Loss_D_A: 0.1935 Loss_D_B: 0.0008\nEpoch [4/50] Batch [4000/5164] Loss_G: 2.7939 Loss_D_A: 0.1899 Loss_D_B: 0.0230\nEpoch [4/50] Batch [4500/5164] Loss_G: 2.6332 Loss_D_A: 0.2542 Loss_D_B: 0.0014\nEpoch [4/50] Batch [5000/5164] Loss_G: 2.7251 Loss_D_A: 0.2524 Loss_D_B: 0.0028\nSaved models for epoch 4\nCompleted epoch 4/50\nEpoch [5/50] Batch [0/5164] Loss_G: 2.8023 Loss_D_A: 0.1235 Loss_D_B: 0.0031\nEpoch [5/50] Batch [500/5164] Loss_G: 2.6537 Loss_D_A: 0.1396 Loss_D_B: 0.0029\nEpoch [5/50] Batch [1000/5164] Loss_G: 2.9388 Loss_D_A: 0.1011 Loss_D_B: 0.0009\nEpoch [5/50] Batch [1500/5164] Loss_G: 3.2123 Loss_D_A: 0.1589 Loss_D_B: 0.0007\nEpoch [5/50] Batch [2000/5164] Loss_G: 3.7016 Loss_D_A: 0.0718 Loss_D_B: 0.0061\nEpoch [5/50] Batch [2500/5164] Loss_G: 3.1870 Loss_D_A: 0.0879 Loss_D_B: 0.0065\nEpoch [5/50] Batch [3000/5164] Loss_G: 2.4679 Loss_D_A: 0.1524 Loss_D_B: 0.0020\nEpoch [5/50] Batch [3500/5164] Loss_G: 3.2697 Loss_D_A: 0.1495 Loss_D_B: 0.2358\nEpoch [5/50] Batch [4000/5164] Loss_G: 3.0379 Loss_D_A: 0.1693 Loss_D_B: 0.0008\nEpoch [5/50] Batch [4500/5164] Loss_G: 2.6934 Loss_D_A: 0.1254 Loss_D_B: 0.0011\nEpoch [5/50] Batch [5000/5164] Loss_G: 2.6408 Loss_D_A: 0.1188 Loss_D_B: 0.0012\nSaved models for epoch 5\nCompleted epoch 5/50\nEpoch [6/50] Batch [0/5164] Loss_G: 2.9810 Loss_D_A: 0.0539 Loss_D_B: 0.0026\nEpoch [6/50] Batch [500/5164] Loss_G: 2.5896 Loss_D_A: 0.1240 Loss_D_B: 0.0034\nEpoch [6/50] Batch [1000/5164] Loss_G: 2.4455 Loss_D_A: 0.1596 Loss_D_B: 0.0009\nEpoch [6/50] Batch [1500/5164] Loss_G: 2.7663 Loss_D_A: 0.1293 Loss_D_B: 0.1795\nEpoch [6/50] Batch [2000/5164] Loss_G: 3.4047 Loss_D_A: 0.1281 Loss_D_B: 0.0008\nEpoch [6/50] Batch [2500/5164] Loss_G: 3.1055 Loss_D_A: 0.2858 Loss_D_B: 0.0025\nEpoch [6/50] Batch [3000/5164] Loss_G: 2.4746 Loss_D_A: 0.2129 Loss_D_B: 0.0006\nEpoch [6/50] Batch [3500/5164] Loss_G: 2.5231 Loss_D_A: 0.2246 Loss_D_B: 0.0011\nEpoch [6/50] Batch [4000/5164] Loss_G: 2.3741 Loss_D_A: 0.2041 Loss_D_B: 0.0010\nEpoch [6/50] Batch [4500/5164] Loss_G: 2.5756 Loss_D_A: 0.2177 Loss_D_B: 0.0010\nEpoch [6/50] Batch [5000/5164] Loss_G: 2.4156 Loss_D_A: 0.2310 Loss_D_B: 0.0015\nSaved models for epoch 6\nCompleted epoch 6/50\nEpoch [7/50] Batch [0/5164] Loss_G: 3.0705 Loss_D_A: 0.1652 Loss_D_B: 0.0012\nEpoch [7/50] Batch [500/5164] Loss_G: 2.6871 Loss_D_A: 0.1935 Loss_D_B: 0.0007\nEpoch [7/50] Batch [1000/5164] Loss_G: 2.4284 Loss_D_A: 0.1815 Loss_D_B: 0.0007\nEpoch [7/50] Batch [1500/5164] Loss_G: 2.2512 Loss_D_A: 0.1527 Loss_D_B: 0.0005\nEpoch [7/50] Batch [2000/5164] Loss_G: 2.9832 Loss_D_A: 0.2052 Loss_D_B: 0.2283\nEpoch [7/50] Batch [2500/5164] Loss_G: 2.9343 Loss_D_A: 0.2405 Loss_D_B: 0.0007\nEpoch [7/50] Batch [3000/5164] Loss_G: 2.4870 Loss_D_A: 0.2094 Loss_D_B: 0.0006\nEpoch [7/50] Batch [3500/5164] Loss_G: 2.7342 Loss_D_A: 0.2409 Loss_D_B: 0.0012\nEpoch [7/50] Batch [4000/5164] Loss_G: 2.4640 Loss_D_A: 0.1922 Loss_D_B: 0.0012\nEpoch [7/50] Batch [4500/5164] Loss_G: 2.7539 Loss_D_A: 0.2035 Loss_D_B: 0.0007\nEpoch [7/50] Batch [5000/5164] Loss_G: 2.6639 Loss_D_A: 0.1939 Loss_D_B: 0.0006\nSaved models for epoch 7\nCompleted epoch 7/50\nEpoch [8/50] Batch [0/5164] Loss_G: 2.7293 Loss_D_A: 0.1549 Loss_D_B: 0.0043\nEpoch [8/50] Batch [500/5164] Loss_G: 2.3975 Loss_D_A: 0.2103 Loss_D_B: 0.0006\nEpoch [8/50] Batch [1000/5164] Loss_G: 2.7428 Loss_D_A: 0.1570 Loss_D_B: 0.0012\nEpoch [8/50] Batch [1500/5164] Loss_G: 2.5765 Loss_D_A: 0.2282 Loss_D_B: 0.0006\nEpoch [8/50] Batch [2000/5164] Loss_G: 1.7390 Loss_D_A: 0.1413 Loss_D_B: 0.1285\nEpoch [8/50] Batch [2500/5164] Loss_G: 2.7287 Loss_D_A: 0.1417 Loss_D_B: 0.0004\nEpoch [8/50] Batch [3000/5164] Loss_G: 2.3068 Loss_D_A: 0.2206 Loss_D_B: 0.0004\nEpoch [8/50] Batch [3500/5164] Loss_G: 2.4739 Loss_D_A: 0.1433 Loss_D_B: 0.0004\nEpoch [8/50] Batch [4000/5164] Loss_G: 3.1523 Loss_D_A: 0.1492 Loss_D_B: 0.0023\nEpoch [8/50] Batch [4500/5164] Loss_G: 3.0829 Loss_D_A: 0.1617 Loss_D_B: 0.0015\nEpoch [8/50] Batch [5000/5164] Loss_G: 2.9411 Loss_D_A: 0.2508 Loss_D_B: 0.0006\nSaved models for epoch 8\nCompleted epoch 8/50\nEpoch [9/50] Batch [0/5164] Loss_G: 2.6239 Loss_D_A: 0.1243 Loss_D_B: 0.0006\nEpoch [9/50] Batch [500/5164] Loss_G: 3.2078 Loss_D_A: 0.1127 Loss_D_B: 0.0017\nEpoch [9/50] Batch [1000/5164] Loss_G: 2.3357 Loss_D_A: 0.2226 Loss_D_B: 0.0006\nEpoch [9/50] Batch [1500/5164] Loss_G: 2.4391 Loss_D_A: 0.2108 Loss_D_B: 0.0042\nEpoch [9/50] Batch [2000/5164] Loss_G: 2.3906 Loss_D_A: 0.1809 Loss_D_B: 0.0005\nEpoch [9/50] Batch [2500/5164] Loss_G: 2.2956 Loss_D_A: 0.1695 Loss_D_B: 0.0175\nEpoch [9/50] Batch [3000/5164] Loss_G: 2.7560 Loss_D_A: 0.1259 Loss_D_B: 0.0019\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 311\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Total loss\u001b[39;00m\n\u001b[1;32m    310\u001b[0m loss_G \u001b[38;5;241m=\u001b[39m loss_identity_A \u001b[38;5;241m+\u001b[39m loss_identity_B \u001b[38;5;241m+\u001b[39m loss_GAN_A2B \u001b[38;5;241m+\u001b[39m loss_GAN_B2A \u001b[38;5;241m+\u001b[39m loss_cycle_ABA \u001b[38;5;241m+\u001b[39m loss_cycle_BAB\n\u001b[0;32m--> 311\u001b[0m \u001b[43mloss_G\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m###### Discriminator A ######\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define the source and destination directories\ncheckpoint_dir = '/kaggle/working/checkpoints'\noutput_dir = '/kaggle/working'\n\n# Get the latest model checkpoint files based on epoch number\ncheckpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\nlatest_checkpoint = max(checkpoint_files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n\n# Copy the latest checkpoint to output directory for download\nshutil.copy(os.path.join(checkpoint_dir, latest_checkpoint), output_dir)\nprint(f\"Copied {latest_checkpoint} to output directory.\")\n\n# Print download link\nfrom IPython.display import FileLink\nprint(\"Click the link below to download the checkpoint:\")\nFileLink(os.path.join(output_dir, latest_checkpoint))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T17:54:44.767267Z","iopub.execute_input":"2024-10-19T17:54:44.767960Z","iopub.status.idle":"2024-10-19T17:54:44.790110Z","shell.execute_reply.started":"2024-10-19T17:54:44.767916Z","shell.execute_reply":"2024-10-19T17:54:44.789246Z"}},"outputs":[{"name":"stdout","text":"Copied D_B_epoch_8.pth to output directory.\nClick the link below to download the checkpoint:\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/D_B_epoch_8.pth","text/html":"<a href='/kaggle/working/D_B_epoch_8.pth' target='_blank'>/kaggle/working/D_B_epoch_8.pth</a><br>"},"metadata":{}}],"execution_count":7}]}